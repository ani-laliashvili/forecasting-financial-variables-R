---
title: "Untitled"
author: "Ani Laliashvili"
date: "5/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This R program can be used interactively to forecast an ARIMA process.

The 'forecast' package does a nice job of working with the data and forecasting.


```{r}
library(readxl)
data10 <- read_excel("c:/Users/anila/OneDrive/Desktop/Forecasting/Final/ARIMA/DGS10.xls")
View(data10)
library(forecast)
```
Now, organize the data as a time series. 

```{r}
x <- data10[,3]
y <- ts(data = x, start = c(1962,2), frequency = 4, end = c(2019,4)) # data start in 1962Q1 and end in 2019Q4.
#y 

```

Begin with a plot.

```{r}
plot(y)
```

Let's take out the mean and calculate the ac's and pac's. 

```{r}
R_mean <- lm(y ~ 1)
BIC(R_mean)
AIC(R_mean)
RES_mean <- residuals.lm(R_mean)
plot(RES_mean)
Acf(RES_mean)
Pacf(RES_mean)


```

Note that the ac's die out very slowly, but the pac's don't go away after the first one, still suggesting a possibility of a unit root.

Let's run the KPSS test. This tells us how many unit roots must be taken out to make the series stationary. 

```{r}
ndiffs(RES_mean,test="kpss")


```

This says that according to the KPSS test there is one unit root.

A similar method for the ADF test.

```{r}
ndiffs(RES_mean,test="adf")
```

The ADF test also says that taking out only 1 unit root is needed to make it stationary.

Let's take out one unit root and reexamine the ac's and pac's to see if it looks like a unit root or not.


This does not look  like a unit root, so it appears that taking out only 1 unit root is enough.


No unit roots remain, so we can now proceed with our normal procedures for ARIMA modeling.

Now we will compare the trend model with the mean model.

A trend comes from regressing the variable on a vector of length N, numbered 1 to N, plus a constant.



```{r}
trend <- lm(RES_mean ~ c(1:length(RES_mean)))
summary(trend)
```

```{r}
AIC(trend)
```

```{r}
BIC(trend)
```

```{r}
REStrend <- residuals(trend)
plot(REStrend)
```

We have found that R_D1 model is better.


Now, let's look at the ac's and pac's. 


```{r}

Acf(RES_mean)

```

Here are the pac's.

```{r}
Pacf(RES_mean)
```
Note that there is 1 significant ac, which suggests MA(1). After the first pac, which is always 1, there are 0 significant pac, so that suggests an AR(0).

So, we start with an MA(1) and go from there.

```{r}
auto.arima(y, seasonal=FALSE, approximation=FALSE, ic = "bic", stepwise=FALSE)
```

```{r}
R2 <- Arima(RES_mean, order = c(0,0,1)) 
summary(R2)

```
Note that the BIC decreased from the original, so the MA(1) model is better than the original.

Next, let's try adding an AR term to see if that helps or hurts.

Note that we have bracketed the BIC minimum with an ARIMA(0,1,1). We have tried ARIMA(0,1,0), ARIMA(0,1,2), ARIMA(1,1,1), ARIMA(1,1,0) and all have higher BIC. So stop here for BIC. 


The BIC best model is ARIMA(1,1,1).

Now let's check the residuals for white noise 


```{r}
checkresiduals(R2)
```


The residuals are somewhat close to white noise but the Ljung-Box test rejects the null hypothesis of white noise at the .05 confidence level. 

Next, letâ€™s forecast two years (8 quarters) ahead.

```{r}
plot(forecast(R2,h=8))
forR400 <- forecast(R2, h = 8) 
print(forR400)
```


